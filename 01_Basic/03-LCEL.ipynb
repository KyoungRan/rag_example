{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f512b08b",
   "metadata": {},
   "source": [
    "## 기본 예시: 프롬프트 + 모델 + 출력파서\n",
    "가장 기본적이고 일반적인 사용 사례는 prompt 템플릿과 모델을 함께 연결하는 것이다. 이것이 어떻게 작동하는지 보기 위해, 각 나라별 수도를  물어보는 chain을 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cbc435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "project_name = \"CH01-Basic\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee5d99d",
   "metadata": {},
   "source": [
    "## 프롬프트 템플릿의 활용\n",
    "```PromptTemplate```\n",
    "- 사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는데 사용되는 템플릿\n",
    "- 사용법\n",
    "    - ```template```: 템플릿 문자열. 이 문자열 내에서 중괄호 ```{}```는 변수를 나타낸다.\n",
    "    - ```input_variables```: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의한다.\n",
    "```input_variables```\n",
    "- input_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e5b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36828a75",
   "metadata": {},
   "source": [
    "```from_template()``` 메소드를 사용하여 PromptTemplate 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6c16f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "# from_template 메소드를 이용하여 PromptTemplate 객체 생성\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0889d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"대한민국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b202b8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미국의 수도는 어디인가요?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt 생성\n",
    "prompt = prompt_template.format(country=\"미국\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96fd16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    model=\"gpt-4.1-nano\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfb1c11",
   "metadata": {},
   "source": [
    "## Chain 생성\n",
    "### LCEL(LangChain Expression Language)\n",
    "![lcel.png](./images/lcel.png)\n",
    "여기서 우리는 LCEL을 사용하여 다양한 구성 요소를 단일 체인으로 결합한다.\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "`|` 기호는 [unix 파이프 연산자](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>)와 유사. 서로 다른 구성 요소를 연결하고 한 구성 요소의 출력을 다음 구성 요소의 입력으로 전달.\n",
    "\n",
    "이 체인에서 사용자 입력은 프롬프트 템플릿으로 전달되고, 그다음  프롬프트 템플릿 출력은 모델로 전달된다. 각 구성 요소를 개별적으로 살펴보면 무슨 일이 일어나고있는지 이해할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe817eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt를 PromptTemplate 객체로 생성\n",
    "prompt = PromptTemplate.from_template(\"{topic}에 대해 {how} 설명해주세요.\")\n",
    "model = ChatOpenAI()\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a26b961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['how', 'topic'], input_types={}, partial_variables={}, template='{topic}에 대해 {how} 설명해주세요.')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f29c190>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f29cb10>, root_client=<openai.OpenAI object at 0x10f293a90>, root_async_client=<openai.AsyncOpenAI object at 0x10f29c550>, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fee31b",
   "metadata": {},
   "source": [
    "### invoke() 호출\n",
    "- python 딕셔너리 형태로 입력값을 전달(키:값)\n",
    "- invoke() 함수 호출 시, 입력값을 전달."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52aadf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input 딕셔너리에 주제를 '인공지능 모델의 학습 원리'으로 설정\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\", \"how\": \"간단하게\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60d043ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 객체와 model 객체를 파이프() 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달\n",
    "# 이를 통해 AI 모델이 생성한 메시지를 반환한다.\n",
    "answer = chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78d4202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 데이터를 입력으로 받아들이고, 이를 분석하고 학습하여 원하는 결과를 출력하는 과정입니다. 주어진 데이터를 토대로 모델은 일련의 수학적인 계산을 통해 학습을 진행하고, 입력 데이터와 출력 데이터 사이의 관계를 학습하여 모델을 최적화합니다. 이를 통해 유사한 데이터가 입력되었을 때 모델은 새로운 결과를 예측할 수 있게 됩니다. 이러한 학습 과정을 지도학습, 비지도학습, 강화학습 등의 방법으로 구분할 수 있습니다.\n",
      "{'token_usage': {'completion_tokens': 195, 'prompt_tokens': 35, 'total_tokens': 230, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CN2rrH6ky8l6sB314JNpdLhBxDI2W', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)\n",
    "print(answer.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6c29c",
   "metadata": {},
   "source": [
    "아래는 스트리밍 출력하는 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7901fb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습은 데이터를 입력으로 받아 원하는 결과를 출력할 수 있도록 모델을 최적화하는 과정입니다. 이를 위해서 먼저 모델 구조를 정의하고 초기화하여 학습을 시작합니다. \n",
      "\n",
      "모델은 입력 데이터를 받아 다양한 수학적 연산을 통해 중간 특성을 추출하고, 최종적으로 원하는 결과를 출력합니다. 이때 모델 내부의 매개변수들이 학습되는데, 이는 입력 데이터와 실제 출력값 간의 차이를 최소화하는 방향으로 조절됩니다. \n",
      "\n",
      "학습은 다수의 반복 과정을 통해 이루어지는데, 각 반복마다 입력 데이터를 모델에 주입하고 출력값과 실제값의 차이를 계산하여 이를 최소화하는 방향으로 모델의 매개변수를 업데이트합니다. 이러한 과정을 통해 모델은 입력 데이터에 대한 패턴을 학습하고, 새로운 데이터에 대해서도 정확한 예측을 할 수 있도록 최적화됩니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import stream_response\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad57a9",
   "metadata": {},
   "source": [
    "### 출력파서(Output Parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf12921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb92d72",
   "metadata": {},
   "source": [
    "Chain에 출력파서를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f24e261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성한다\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcddb29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'인공지능 모델의 학습 원리는 크게 지도학습, 비지도학습, 강화학습으로 나눌 수 있습니다.\\n\\n1. 지도학습(Supervised Learning): 인공지능 모델이 입력 데이터와 정답 데이터가 함께 제공되는 상황에서 학습을 진행하는 방법입니다. 모델은 입력 데이터를 받아들인 후 정답 데이터와 비교하여 오차를 계산하고, 이 오차를 최소화하는 방향으로 모델의 가중치를 조정해나갑니다. 가장 대표적인 지도학습 알고리즘에는 선형 회귀, 로지스틱 회귀, 신경망 등이 있습니다.\\n\\n2. 비지도학습(Unsupervised Learning): 입력 데이터만을 가지고 학습을 진행하는 방법으로, 정답 데이터가 없는 상황에서 적용됩니다. 모델은 입력 데이터의 특성이나 구조를 파악하고자 노력하며, 주로 데이터의 군집화(clustering)나 차원 축소(dimensionality reduction)에 사용됩니다. 대표적인 비지도학습 알고리즘으로는 K-평균 군집화, PCA(주성분 분석), 오토인코더 등이 있습니다.\\n\\n3. 강화학습(Reinforcement Learning): 환경과 상호작용하며 학습을 진행하는 방법으로, 보상을 최대화하는 방향으로 행동을 선택하는 방법입니다. 모델은 시행착오를 통해 보상을 최적화하는 방향으로 학습하며, 대표적인 알고리즘으로는 Q-Learning, Deep Q-Network(DQN), 강화학습을 활용한 신경망 등이 있습니다.\\n\\n이러한 방법들을 조합하여 다양한 분야에 적용되는 인공지능 모델을 학습시키고, 최적의 성능을 얻는 것이 학습의 핵심 원리입니다.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain 객체의 invoke 메소드를 사용하여 input을 전달한다\n",
    "input = {\"topic\": \"인공지능 모델의 학습 원리\",  \"how\": \"전문적으로\"}\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "818ba75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 크게 지도 학습, 비지도 학습, 강화 학습으로 나눌 수 있습니다.\n",
      "\n",
      "1. 지도 학습 (Supervised Learning):\n",
      "지도 학습은 입력 데이터와 해당 데이터에 대한 레이블(정답)이 함께 제공되는 방식으로 모델을 학습시키는 방법입니다. 모델은 입력 데이터와 레이블 간의 관계를 학습하여 새로운 입력 데이터에 대한 예측을 할 수 있습니다. 예를 들어, 고양이 사진과 해당 사진이 고양이인지 아닌지에 대한 레이블을 제공하고 모델을 학습시키는 것이 지도 학습의 예시입니다.\n",
      "\n",
      "2. 비지도 학습 (Unsupervised Learning):\n",
      "비지도 학습은 레이블이 주어지지 않은 데이터를 활용하여 모델을 학습시키는 방법입니다. 모델은 데이터 간의 패턴이나 특징을 발견하여 데이터를 그룹화하거나 차원을 축소하는 등의 작업을 수행합니다. 예를 들어, 클러스터링이나 차원 축소를 통해 데이터를 이해하는 것이 비지도 학습의 예시입니다.\n",
      "\n",
      "3. 강화 학습 (Reinforcement Learning):\n",
      "강화 학습은 에이전트가 환경과 상호작용하면서 보상을 최대화하는 방향으로 학습하는 방법입니다. 에이전트는 특정 상태에서 특정 행동을 취함으로써 보상을 얻게 되고, 이를 토대로 학습하여 미래에 높은 보상을 얻을 수 있는 행동을 선택하도록 합니다. 예를 들어, 게임에서 이길 확률을 높이기 위해 강화 학습을 이용하여 게임을 플레이하는 것이 강화 학습의 예시입니다.\n",
      "\n",
      "이렇게 다양한 학습 방법을 통해 모델은 입력 데이터의 패턴을 학습하고 문제를 해결할 수 있도록 개선됩니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream(input)\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2a9df4",
   "metadata": {},
   "source": [
    "### 템플릿을 변경하여 적용\n",
    "- 아래의 프롬프트 내용을 얼마든지 변경하여 테스트 해볼 수 있다.\n",
    "- ```model_name``` 역시 변경하여 테스트가 가능하다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48fc3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\n",
    "양식은 [FORMAT]을 참고하여 작성해 주세요.\n",
    "\n",
    "#상황:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- 영어 회화:\n",
    "- 한글 해석:\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 이용하여 프롬프트를 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# ChatOpenAI 챗모델을 초기화\n",
    "model = ChatOpenAI(model_name=\"gpt-4-turbo\")\n",
    "\n",
    "# 문자열 출력 파서를 초기화\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09dd02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 구성한다\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "116f99da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='\\n당신은 영어를 가르치는 10년차 영어 선생님입니다. 주어진 상황에 맞는 영어 회화를 작성해 주세요.\\n양식은 [FORMAT]을 참고하여 작성해 주세요.\\n\\n#상황:\\n{question}\\n\\n#FORMAT:\\n- 영어 회화:\\n- 한글 해석:\\n')\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10f629ad0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10f644310>, root_client=<openai.OpenAI object at 0x10d9ab350>, root_async_client=<openai.AsyncOpenAI object at 0x10f556390>, model_name='gpt-4-turbo', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdfcdceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화: \n",
      "  \"Hi, I'd like to start with some water, please. Could I see the menu? Thank you. I think I'll go for the grilled salmon with a side of steamed vegetables. Does that come with any sauce?\"\n",
      "  \n",
      "- 한글 해석:\n",
      "  \"안녕하세요, 물부터 시작할게요. 메뉴판 좀 볼 수 있을까요? 감사합니다. 저는 구운 연어에 찐 채소를 곁들인 것으로 주문할게요. 그 음식에 소스가 따로 나오나요?\"\n"
     ]
    }
   ],
   "source": [
    "# 완성된 Chain을 실행하여 답변을 얻는다\n",
    "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaabb58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "  A: Hi, I’d like to order a pizza for delivery, please.\n",
      "  B: Sure, what would you like?\n",
      "  A: I’d like a large pepperoni pizza with extra cheese.\n",
      "  B: Would you like any sides or drinks?\n",
      "  A: Yes, can I have an order of garlic bread and two Diet Cokes?\n",
      "  B: Absolutely. Can I have your delivery address please?\n",
      "  A: It’s 452 Park Avenue, Apartment 21B.\n",
      "  B: Great, your total will be $24.50. Is there anything else?\n",
      "  A: No, that’s all. How long will the delivery take?\n",
      "  B: It should take about 30-40 minutes. We’ll get it to you as soon as possible.\n",
      "  A: Sounds good, thank you!\n",
      "\n",
      "- 한글 해석:\n",
      "  A: 안녕하세요, 배달로 피자 주문하고 싶습니다.\n",
      "  B: 네, 무엇을 드릴까요?\n",
      "  A: 대형 페페로니 피자에 치즈를 추가해 주세요.\n",
      "  B: 사이드 메뉴나 음료는 필요하신가요?\n",
      "  A: 예, 마늘빵 하나와 다이어트 콜라 두 개 주세요.\n",
      "  B: 알겠습니다. 배달 주소 알려주시겠어요?\n",
      "  A: 452 파크 애비뉴, 21B 아파트입니다.\n",
      "  B: 좋습니다, 총 금액은 $24.50입니다. 다른 것 필요하신 건 없나요?\n",
      "  A: 아니요, 그게 다입니다. 배달은 얼마나 걸리나요?\n",
      "  B: 대략 30-40분 걸릴 예정입니다. 최대한 빨리 배달해 드리겠습니다.\n",
      "  A: 좋습니다, 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "# 이번에는 question을 \"미국에서 피자 주문\"으로 설정하여 실행한다\n",
    "print(chain.invoke({\"question\": \"미국에서 피자 주문\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f118d01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 영어 회화:\n",
      "   - Server: \"Hello! Welcome to our restaurant. Are you ready to order or do you need a few more minutes?\"\n",
      "   - You: \"Hi, I think I need a couple more minutes. Could I get a glass of water, please?\"\n",
      "   - Server: \"Of course! I’ll bring your water right away. Just let me know when you’re ready to order.\"\n",
      "   - You: \"Thank you. Actually, can I ask about today’s specials?\"\n",
      "   - Server: \"Today we have grilled salmon with a lemon butter sauce and a side of asparagus, or there’s a roasted chicken served with mashed potatoes and gravy.\"\n",
      "   - You: \"That sounds delicious. I’ll have the grilled salmon, please.\"\n",
      "   - Server: \"Great choice! How would you like the salmon cooked?\"\n",
      "   - You: \"Could I have it cooked medium, please?\"\n",
      "   - Server: \"Sure thing. Would you like anything to drink with your meal?\"\n",
      "   - You: \"Yes, I’ll have a glass of white wine. Could you recommend one?\"\n",
      "   - Server: \"Certainly! The Chardonnay pairs very well with our salmon. It’s light and refreshing.\"\n",
      "   - You: \"That sounds perfect. I’ll go with the Chardonnay, thank you.\"\n",
      "   - Server: \"Excellent choice. I’ll get your order started and bring the wine right over.\"\n",
      "   - You: \"Thank you very much.\"\n",
      "\n",
      "- 한글 해석:\n",
      "   - 웨이터: \"안녕하세요! 저희 식당에 오신 것을 환영합니다. 주문하실 준비가 되셨나요, 아니면 몇 분 더 필요하신가요?\"\n",
      "   - 당신: \"안녕하세요, 몇 분 더 필요할 것 같아요. 물 한 잔 주실 수 있나요?\"\n",
      "   - 웨이터: \"물론입니다! 물을 곧 가져다 드리겠습니다. 주문 준비가 되시면 알려주세요.\"\n",
      "   - 당신: \"감사합니다. 오늘의 특선 메뉴가 무엇인지 여쭐 수 있을까요?\"\n",
      "   - 웨이터: \"오늘은 레몬 버터 소스를 곁들인 연어 구이와 아스파라거스가 있으며, 또는 로스트 치킨이 감자 퓌레와 그레이비와 함께 제공됩니다.\"\n",
      "   - 당신: \"정말 맛있겠네요. 연어 구이 주세요.\"\n",
      "   - 웨이터: \"좋은 선택입니다! 연어는 어떻게 익혀 드릴까요?\"\n",
      "   - 당신: \"중간 정도로 익혀 주세요.\"\n",
      "   - 웨이터: \"알겠습니다. 식사와 함께 드실 음료는 어떤 걸로 하시겠어요?\"\n",
      "   - 당신: \"네, 화이트 와인 한 잔 주세요. 추천해 주실 수 있나요?\"\n",
      "   - 웨이터: \"물론이죠! 샤르도네 와인이 연어와 아주 잘 어울립니다. 가볍고 상쾌해요.\"\n",
      "   - 당신: \"완벽해요. 샤르도네로 주세요. 감사합니다.\"\n",
      "   - 웨이터: \"훌륭한 선택이십니다. 주문을 시작하겠습니다. 곧 와인을 가져다 드리겠습니다.\"\n",
      "   - 당신: \"정말 감사합니다.\""
     ]
    }
   ],
   "source": [
    "# 완성된 chain을 실행하여 답변을 얻는다\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"})\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22254a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#상황:\n",
      "미국에서 피자 주문\n",
      "\n",
      "#FORMAT:\n",
      "- 영어 회화:\n",
      "   **Customer:** Hi, I’d like to order a large pepperoni pizza for delivery, please.\n",
      "   **Operator:** Sure thing! Can I get your address, please?\n",
      "   **Customer:** It’s 124 Elm Street, Apartment 7, Springfield.\n",
      "   **Operator:** Great! And would you like to add any sides or drinks to your order?\n",
      "   **Customer:** Yes, let’s add a side of garlic knots and two cans of Coke.\n",
      "   **Operator:** Perfect! That’s a large pepperoni pizza, garlic knots, and two Cokes. Will that be all?\n",
      "   **Customer:** Yes, that’s it. How long will the delivery take?\n",
      "   **Operator:** It should be there in about 30-45 minutes. The total comes to $28.50. Is that alright?\n",
      "   **Customer:** That sounds good. Can I pay with a credit card?\n",
      "   **Operator:** Of course. I can take your card information now.\n",
      "   **Customer:** Sure, the number is 1234 5678 9012 3456, expiration date 04/24, and the CVV is 789.\n",
      "   **Operator:** Thank you! Your order has been placed and should arrive within the next 45 minutes. Have a great day!\n",
      "\n",
      "- 한글 해석:\n",
      "   **고객:** 안녕하세요, 배달로 라지 사이즈의 페퍼로니 피자 한 판 주문하고 싶습니다.\n",
      "   **주문 접수자:** 네, 주소를 알려주시겠어요?\n",
      "   **고객:** 124 엘름 스트리트, 7호 아파트, 스프링필드입니다.\n",
      "   **주문 접수자:** 좋습니다! 사이드 메뉴나 음료도 추가로 주문하시겠어요?\n",
      "   **고객:** 네, 갈릭 노트 한 개와 콜라 두 캔 추가해주세요.\n",
      "   **주문 접수자:** 알겠습니다! 그러면 페퍼로니 피자 라지 사이즈, 갈릭 노트, 그리고 콜라 두 캔입니다. 이게 다 맞나요?\n",
      "   **고객:** 네, 그게 다입니다. 배달은 얼마나 걸리나요?\n",
      "   **주문 접수자:** 대략 30-45분 정도 걸릴 예정입니다. 총 금액은 $28.50입니다. 괜찮으신가요?\n",
      "   **고객:** 좋습니다. 신용카드로 결제할 수 있나요?\n",
      "   **주문 접수자:** 물론입니다. 지금 카드 정보를 알려주세요.\n",
      "   **고객:** 네, 카드 번호는 1234 5678 9012 3456이고, 유효 기간은 04/24, CVV는 789입니다.\n",
      "   **주문 접수자:** 감사합니다! 주문이 완료되었고, 45분 이내에 도착할 예정입니다. 좋은 하루 되세요!"
     ]
    }
   ],
   "source": [
    "# 이번에는 question을 \"미국에서 피자 주문\"으로 설정한 것을 스트리밍으로 출력\n",
    "answer1 = chain.stream({\"question\": \"미국에서 피자 주문\"})\n",
    "stream_response(answer1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
